{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[GEMASTIK] QABert.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "vSbjHHIQ5QiU",
        "9o1qZEIt5Sbc"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCRYx78627b4"
      },
      "source": [
        "# Depedencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tByuyeB42-Ce"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rS8yyUyr16uK",
        "outputId": "c58fecce-1a21-4f76-89d9-cf161d170f55"
      },
      "source": [
        "!pip3 install transformers\n",
        "!pip3 install torch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.11.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.18)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: ruamel.yaml==0.17.16 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (0.17.16)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.1.2 in /usr/local/lib/python3.7/dist-packages (from ruamel.yaml==0.17.16->huggingface-hub>=0.0.17->transformers) (0.2.6)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8HkBz0V2hbb"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from transformers import BertForQuestionAnswering, BertTokenizer, BertConfig\n",
        "\n",
        "import seaborn as sns \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiEyjpQD2_NZ"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gI7hL0oT2oKk",
        "outputId": "0fce5d9d-cc66-40b4-cb37-ed34e3be7e77"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZk6pRYt2oZZ"
      },
      "source": [
        "TRAIN_PATH = '/content/drive/MyDrive/Data Science/Project/GEMASTIK 2021/Final/train_preprocess.csv'\n",
        "VAL_PATH = '/content/drive/MyDrive/Data Science/Project/GEMASTIK 2021/Final/valid_preprocess.csv'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSNl86Pf24zw"
      },
      "source": [
        "train = pd.read_csv(TRAIN_PATH)\n",
        "val = pd.read_csv(VAL_PATH)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69JjPOI23IDD"
      },
      "source": [
        "# Pre-Process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSbjHHIQ5QiU"
      },
      "source": [
        "## Question and Passage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "hiBThwsk3F4L",
        "outputId": "4fd13fd6-b86f-4444-9de5-5693ac0ac617"
      },
      "source": [
        "train.sample(1)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>passage</th>\n",
              "      <th>seq_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1501</th>\n",
              "      <td>['Berapa', 'orangkah', 'anggota', 'Dewan', 'IA...</td>\n",
              "      <td>['Resolusi', 'IAEA', 'itu', 'pada', 'dasarnya'...</td>\n",
              "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               question  ...                                          seq_label\n",
              "1501  ['Berapa', 'orangkah', 'anggota', 'Dewan', 'IA...  ...  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...\n",
              "\n",
              "[1 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrvVzNE54AGe"
      },
      "source": [
        "train['question'] = train['question'].apply(lambda x: \" \".join(eval(x)))\n",
        "train['passage'] = train['passage'].apply(lambda x: \" \".join(eval(x)))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "S2jYspiu3f6I",
        "outputId": "ed972199-9c58-4fdd-a0dc-f57699d46ae9"
      },
      "source": [
        "train.sample(1)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>passage</th>\n",
              "      <th>seq_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1361</th>\n",
              "      <td>apa nama latin biawak</td>\n",
              "      <td>Ketika tim tiba siang hari , para orangutan it...</td>\n",
              "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   question  ...                                          seq_label\n",
              "1361  apa nama latin biawak  ...  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...\n",
              "\n",
              "[1 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9o1qZEIt5Sbc"
      },
      "source": [
        "## Sequence Label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIgqypuo5QMM"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "import nltk"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Djq_N_y5kaM",
        "outputId": "f6e46761-59ae-4ce8-979b-4e6dde3addeb"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3jyG6gQ5VQD"
      },
      "source": [
        "def BI(seq_label):\n",
        "    B_idx, I_idx = 0,0\n",
        "    curr_idx = 0\n",
        "    for i in seq_label.replace(\"', '\", \"\").replace(\"['\", \"\").replace(\"']\", \"\"):\n",
        "        if i == 'B':\n",
        "            B_idx = curr_idx \n",
        "        if i == 'I':\n",
        "            I_idx = curr_idx \n",
        "        curr_idx += 1\n",
        "\n",
        "    return B_idx, I_idx"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjtMdoW15YKI"
      },
      "source": [
        "train['tokenized'] = train['passage'].apply(word_tokenize)\n",
        "\n",
        "train['answer'] = np.nanargmax\n",
        "for idx, rows in train.iterrows():\n",
        "    B, I = BI(rows['seq_label'])\n",
        "    if I == 0:\n",
        "        rows['answer'] = rows[\"tokenized\"][B]\n",
        "    else:\n",
        "        rows['answer'] = \" \".join(rows[\"tokenized\"][B:I+1])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rD-FBM035o80"
      },
      "source": [
        "train.drop(['seq_label', 'tokenized'], axis=1, inplace=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "xDX7DCKu5ba3",
        "outputId": "aa7464ec-734f-4192-ce01-100e29ac9129"
      },
      "source": [
        "train.sample(1)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>passage</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2192</th>\n",
              "      <td>Siapakah Mantan Deputi Perdana Menteri Malaysi...</td>\n",
              "      <td>Kuala lumpur , kamis - Mantan Deputi Perdana M...</td>\n",
              "      <td>Anwar Ibrahim</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               question  ...         answer\n",
              "2192  Siapakah Mantan Deputi Perdana Menteri Malaysi...  ...  Anwar Ibrahim\n",
              "\n",
              "[1 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cq6iMwJN5xh6"
      },
      "source": [
        "# Input Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8F5ZLvvz7k0P"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6yWhZLu7lza",
        "outputId": "29e828ed-215d-489b-c933-afe6a071a6c2"
      },
      "source": [
        "MODEL_NAME = \"indobenchmark/indobert-base-p2\"\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = BertForQuestionAnswering.from_pretrained(MODEL_NAME)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hl0GSDdC_Ayt"
      },
      "source": [
        "from transformers import BertConfig\n",
        "\n",
        "# Initializing a BERT bert-base-uncased style configuration\n",
        "configuration = BertConfig()\n",
        "\n",
        "# Initializing a model from the bert-base-uncased style configuration\n",
        "model = BertForQuestionAnswering(configuration)\n",
        "\n",
        "# Accessing the model configuration\n",
        "configuration = model.config"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98zq4cYnI44m",
        "outputId": "5f98bf58-4cb4-45c2-d449-ae52e4e82db6"
      },
      "source": [
        "configuration"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertConfig {\n",
              "  \"attention_probs_dropout_prob\": 0.1,\n",
              "  \"classifier_dropout\": null,\n",
              "  \"hidden_act\": \"gelu\",\n",
              "  \"hidden_dropout_prob\": 0.1,\n",
              "  \"hidden_size\": 768,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 3072,\n",
              "  \"layer_norm_eps\": 1e-12,\n",
              "  \"max_position_embeddings\": 512,\n",
              "  \"model_type\": \"bert\",\n",
              "  \"num_attention_heads\": 12,\n",
              "  \"num_hidden_layers\": 12,\n",
              "  \"pad_token_id\": 0,\n",
              "  \"position_embedding_type\": \"absolute\",\n",
              "  \"transformers_version\": \"4.11.2\",\n",
              "  \"type_vocab_size\": 2,\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 30522\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5Zoeakf7PSI"
      },
      "source": [
        "## Instance Trial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Hy76VZf5nGp",
        "outputId": "2dcfebd6-a65f-423e-8e7d-c3c8bebb6e43"
      },
      "source": [
        "question = train['question'][0]\n",
        "passage = train['passage'][0]\n",
        "\n",
        "print(\"Question: {}\".format(question))\n",
        "print(\"Passage: {}\".format(passage))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Kelompok apakah yang menyatakan bertanggung jawab atas ledakan di Srinagar ?\n",
            "Passage: Lewat telepon ke kantor berita lokal Current News Service , Hezb-ul Mujahedeen , kelompok militan Kashmir yang terbesar , menyatakan bertanggung jawab atas ledakan di Srinagar .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2ZyOcIy7cxH",
        "outputId": "ee30f75a-df51-4e47-9dd2-f6318c03ed2f"
      },
      "source": [
        "# Apply tokenizer (Token Ids)\n",
        "input_ids = tokenizer.encode(question, passage)\n",
        "for ids in input_ids:\n",
        "  print(ids, end=\" \")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 1311 937 34 2195 3987 1024 441 10884 26 4750 23620 12 30477 3 2145 3178 43 1571 2140 2752 24072 4425 4266 30468 1991 30387 30368 30469 601 18642 15188 9 30468 1311 26762 575 13461 72 34 2805 30468 2195 3987 1024 441 10884 26 4750 23620 12 30470 3 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ctx61yom7iwy",
        "outputId": "7d273dd4-77a6-4b5e-e7f9-8d4d9deeece9"
      },
      "source": [
        "# String representations of Token Ids\n",
        "tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
        "\n",
        "for token, id in zip(tokens, input_ids):\n",
        "    if id == tokenizer.sep_token_id:\n",
        "        print('')\n",
        "\n",
        "    print('{:<12} {:>6,}'.format(token, id))\n",
        "    if id == tokenizer.sep_token_id:\n",
        "        print('')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS]             2\n",
            "kelompok      1,311\n",
            "apakah          937\n",
            "yang             34\n",
            "menyatakan    2,195\n",
            "bertanggung   3,987\n",
            "jawab         1,024\n",
            "atas            441\n",
            "ledakan      10,884\n",
            "di               26\n",
            "sri           4,750\n",
            "##nag        23,620\n",
            "##ar             12\n",
            "?            30,477\n",
            "\n",
            "[SEP]             3\n",
            "\n",
            "lewat         2,145\n",
            "telepon       3,178\n",
            "ke               43\n",
            "kantor        1,571\n",
            "berita        2,140\n",
            "lokal         2,752\n",
            "current      24,072\n",
            "news          4,425\n",
            "service       4,266\n",
            ",            30,468\n",
            "he            1,991\n",
            "##z          30,387\n",
            "##b          30,368\n",
            "-            30,469\n",
            "ul              601\n",
            "mujah        18,642\n",
            "##ede        15,188\n",
            "##en              9\n",
            ",            30,468\n",
            "kelompok      1,311\n",
            "militan      26,762\n",
            "kas             575\n",
            "##hm         13,461\n",
            "##ir             72\n",
            "yang             34\n",
            "terbesar      2,805\n",
            ",            30,468\n",
            "menyatakan    2,195\n",
            "bertanggung   3,987\n",
            "jawab         1,024\n",
            "atas            441\n",
            "ledakan      10,884\n",
            "di               26\n",
            "sri           4,750\n",
            "##nag        23,620\n",
            "##ar             12\n",
            ".            30,470\n",
            "\n",
            "[SEP]             3\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzbWOzNE8Gwt",
        "outputId": "ad1679f2-b0d1-4398-954e-7e364e6a4c98"
      },
      "source": [
        "# Question and passage segmentation\n",
        "sep_index = input_ids.index(tokenizer.sep_token_id)\n",
        "\n",
        "num_seg_a = sep_index + 1\n",
        "num_seg_b = len(input_ids) - num_seg_a\n",
        "\n",
        "segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
        "assert len(segment_ids) == len(input_ids)\n",
        "\n",
        "for ids in segment_ids:\n",
        "  print(ids, end=\" \")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Y8UNJtI8YBj"
      },
      "source": [
        "scores = model(input_ids=torch.tensor([input_ids]), token_type_ids=torch.tensor([segment_ids]))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyY8fr3S_yd8",
        "outputId": "dd3fc60a-851c-4a3a-84d8-50846089afdb"
      },
      "source": [
        "scores"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "QuestionAnsweringModelOutput([('start_logits',\n",
              "                               tensor([[ 0.3262,  0.4315,  0.5480, -0.3025,  0.1049,  0.6590,  0.8419,  0.0899,\n",
              "                                         0.2076,  0.2457,  0.0792, -0.2819,  0.2909,  0.1270,  0.4943,  0.4531,\n",
              "                                         1.2032,  0.8738,  0.6414,  0.8590,  0.5857,  0.8825,  0.5730,  0.2870,\n",
              "                                         1.0768, -0.1091, -0.2752, -0.5461,  0.0358,  0.3461,  0.1188,  0.1227,\n",
              "                                         0.3420,  0.9194,  0.8786,  1.2745,  0.2697,  0.5761, -0.0050, -0.5668,\n",
              "                                         0.9843,  0.3420, -0.4176,  0.5979,  0.5708,  0.7775,  0.7004,  0.5933,\n",
              "                                         0.9412, -0.2885, -0.1101,  0.1245,  0.4167]],\n",
              "                                      grad_fn=<CopyBackwards>)),\n",
              "                              ('end_logits',\n",
              "                               tensor([[-0.4654,  0.3069,  0.7186,  0.5722, -0.1729,  0.6494,  0.3074,  0.9664,\n",
              "                                        -0.0551,  0.0782,  0.4327,  0.6886,  0.3676,  0.0488,  0.2554, -0.5503,\n",
              "                                         0.0603,  0.3223,  0.2011, -0.2725, -0.2138, -0.0542,  0.0241,  0.7324,\n",
              "                                         0.0943, -0.1758,  0.5893,  0.4212, -0.2389, -0.6797,  0.7362,  0.1326,\n",
              "                                         0.5913,  0.1949, -0.0775,  0.1625, -0.2851,  0.2103,  0.8126,  0.1791,\n",
              "                                         0.4960,  0.3821, -0.3666,  0.0751,  0.7110,  0.4924,  0.7237,  1.0145,\n",
              "                                         0.7712,  0.7863,  0.5757,  0.2430,  0.5815]],\n",
              "                                      grad_fn=<CopyBackwards>))])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LyyM34b8hur",
        "outputId": "881a2804-d060-4f63-f32b-d15b3e2511bf"
      },
      "source": [
        "answer_start = torch.argmax(scores['start_logits'])\n",
        "answer_end = torch.argmax(scores['end_logits'])\n",
        "\n",
        "answer = ' '.join(tokens[answer_start:answer_end+1])\n",
        "print('Answer: \"' + answer + '\"')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: \"militan kas ##hm ##ir yang terbesar , menyatakan bertanggung jawab atas ledakan di\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfYmfWYbBm0u",
        "outputId": "ece11e2a-ba62-4dc0-ba6e-f54fe7b61cff"
      },
      "source": [
        "answer = tokens[answer_start]\n",
        "\n",
        "for i in range(answer_start + 1, answer_end + 1):\n",
        "    \n",
        "    if tokens[i][0:2] == '##':\n",
        "        answer += tokens[i][2:]\n",
        "    else:\n",
        "        answer += ' ' + tokens[i]\n",
        "\n",
        "print('Answer: \"' + answer + '\"')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: \"militan kashmir yang terbesar , menyatakan bertanggung jawab atas ledakan di\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuWWbqFmDVzK"
      },
      "source": [
        "## Input Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tafpIFw7Dj4R"
      },
      "source": [
        "class QADataset(Dataset):\n",
        "  def __init__(self, dataframe, tokenizer):\n",
        "    self.len = len(dataframe)\n",
        "    self.data = dataframe\n",
        "    self.tokenizer = tokenizer\n",
        "    self.maxlen = 128\n",
        "\n",
        "  def __get__item(self, index):\n",
        "    question = self.data.question[index]\n",
        "    passage = self.data.question[index]\n",
        "\n",
        "    inputs = tokenizer.encode_plus(question, passage,\n",
        "                                   max_length=128,\n",
        "                                   add_special_tokens=True,\n",
        "                                   pad_to_max_length=True,\n",
        "                                   return_attetion_mask=True,\n",
        "                                   truncation=True)\n",
        "\n",
        "    ids = inputs['input_ids']\n",
        "    segment = inputs['token_type_ids']\n",
        "    mask = inputs['attention_mask']\n",
        "\n",
        "    return {\n",
        "        'ids': torch.tensor([ids], dtype=torch.long),\n",
        "        'segments': torch.tensor([segment], dtype=torch.long),\n",
        "        'mask': torch.tensor([mask], dtype=torch.long)\n",
        "    }\n",
        "  \n",
        "  def __len__(self):\n",
        "    return self.len"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFoOZ5ejFfe8",
        "outputId": "8c1e923d-40e7-42ad-95ba-524b7af34128"
      },
      "source": [
        "trainset = QADataset(train, tokenizer)\n",
        "trainload = DataLoader(trainset)\n",
        "\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-5)\n",
        "\n",
        "trainload"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7fb4aaba01d0>"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjaPql0oFe_t"
      },
      "source": [
        "def evaluate(data, output):\n",
        "    answer = ''\n",
        "    max_prob = float('-inf')\n",
        "    num_of_windows = data[0].shape[1]\n",
        "    \n",
        "    for k in range(num_of_windows):\n",
        "        # Obtain answer by choosing the most probable start position / end position\n",
        "        start_prob, start_index = torch.max(output.start_logits[k], dim=0)\n",
        "        end_prob, end_index = torch.max(output.end_logits[k], dim=0)\n",
        "        \n",
        "        # Probability of answer is calculated as sum of start_prob and end_prob\n",
        "        prob = start_prob + end_prob\n",
        "        \n",
        "        # Replace answer if calculated probability is larger than previous windows\n",
        "        if prob > max_prob:\n",
        "            max_prob = prob\n",
        "            answer = tokenizer.decode(data[0][0][k][start_index : end_index + 1])\n",
        "    \n",
        "    return answer.replace(' ','')"
      ],
      "execution_count": 123,
      "outputs": []
    }
  ]
}